# 정형 데이터의 전처리 3/5

전처리를 통해 얻은 데이터 세트를 가지고 머신러닝 알고리즘을 사용해 모델을 작성합니다. 

이 강의는 전처리 중심의 내용을 다루고 있기 때문에 사용하는 방법을 간단하게만 설명하겠습니다. 

<br>

### 데이터 읽기와 확인

새로운 노트북을 작성하고 앞에서 작성한 CSV 파일을 업로드합니다. 

```python
import pandas as pd
d_df_new = pd.read_csv('b-prep.csv', sep=',')

d_df_new.head()
```

데이터를 로드합니다. 

<br>

### 불균형 데이터의 균형화 

목적변수 y의 데이터 분포는 확인 결과 y가 n보다 압도적으로 데이터 건수가 적다는 것을 확인했습니다. 

이대로 작성하면 no를 검출하는 모델 밖에 작성되지 않습니다. 

그래서 y와 n가 균형을 이루도록 가공해야 합니다. 

<br>

다수 클래스의 데이터 건수를 소수 클래스의 건수와 같게 만들어줍니다. 

다수 건수의 데이터를 혼합하고 소수 클래스의 동일한 건수의 데이터를 선택하면 됩니다. 

이런 과정을 언더샘플링이라고 합니다. 

<br>

imbalanced-learn 패키지를 사용합니다. 

우선 주피터랩에 imbalanced-learn이 설치되어 있는지 확인합니다. 

```python
!pip show imbalanced-learn
```

위의 명령을 실행하여 설치 유무를 확인합니다. 

<br>

설치되어 있지 않은 경우 다음의 명령어를 사용하여 설치합니다. 

```python
!pip install imbalanced-learn
```

Successfully installed 문구가 뜨면 패키지 설치가 완료된 것입니다. 

<br>

이제 불균형 데이터에 대해 언더 샘플링을 작성하겠습니다. 

```python
import numpy as np
from imblearn.under_sampling import RandomUnderSampler

X = np.array(d_df_new.drop('y', axis=1))
Y = np.array(d_df_new['y'])

print(np.sum(Y == 1), np.sum(Y == 0))

sampler = RandomUnderSampler(random_state=42)
X, Y = sampler.fit_resample(X, Y)

print(np.sum(Y == 1), np.sum(Y == 0))
```

numpy와 RandomUnderSampler를 로드합니다. 

y 외의 모든 방목을 설명변수로 하고 X를 신규변수로, y를 목적변수로 해서 신규변수 Y에 저장합니다. 

랜덤 샘플링으로 조건을 설정합니다. 

```
1854 1017
1017 1017
```

실행하여 샘플링 전 후의 데이터 건수를 확인합니다. 

샘플링 후에는 둘다 1017건으로 균형을 이루게 되었습니다. 

<br>

언더 샘플링이 많은 데이터 셋을 적은 데이터 셋 수준으로 감소시키는 방식이라면 그 반대의 개념인 오버 샘플링도 있습니다. 

오버 샘플링은 소수 클래스의 데이터 수를 증가시켜 다수 클래스의 건수와 동일하게 만드는 것 입니다. 

```python
import numpy as np
from imblearn.over_sampling import RandomOverSampler

X = np.array(d_df_new.drop('y', axis=1))
Y = np.array(d_df_new['y'])

print(np.sum(Y == 1), np.sum(Y == 0))

sampler = RandomOverSampler(random_state=42)
X, Y = sampler.fit_resample(X, Y)

print(np.sum(Y == 1), np.sum(Y == 0))
```

RandomOverSampler를 로드합니다. 

랜덤 샘플링을 실행합니다. 

```
1854 1017
1854 1854
```

샘플링 후 둘 다 2281건으로 균형을 이루게 되었습니다. 

<br>

지금 사용한 방법은 데이터를 복사해서 균형을 이루게 만드는 방법입니다. 

하지만 데이터를 복사하지 않고 보완해서 증가시키는 방법이 좀 더 일반적입니다. 

imbalanced-learn에서 제공하는 SMOTE 기법은 k-NN법의 아이디어를 이용하여 데이터를 증가시킵니다. 

SMOTE는 수가 적은 클래스에 주목해서 어떤 데이터 점과 근접한 데이터 점 간에 새로운 데이터 점을 생성하는 것 입니다. 

해당 내용은 추가적으로 학습하시길 바랍니다. 

<br>

### 결정 트리 모델 작성 및 검증

Scikit-leran 을 사용해서 결정 트리 알고리즘 작성

```python

from sklearn.model_selection import KFold
from sklearn import tree
from sklearn.metrics import accuracy_score


kf = KFold(n_splits=10, shuffle=True)

scores = []

for train_id, test_id in kf.split(X):

    x = X[train_id]
    y = Y[train_id]
    clf = tree.DecisionTreeClassifier()
    clf.fit(x,y)

    pred_y = clf.predict(X[test_id])

    score = accuracy_score(Y[test_id], pred_y)
    scores.append(score)

scores = np.array(scores)
print(scores.mean(), scores.std())
```

Scikit-learn에 포함되어 있는 K-폴드 교차 검증, 결정 트리 알고리즘, 성능 개션을 하기 위한 클래스를 각각 로드합니다. 

K-폴드 교차 검증을 실시합니다. 첫 번째 인자에는 데이터세트를 분할하는 갯수 10, 두 번째 인자에는 데이터 세트를 재생하도록 지정합니다. 

혼련 데이터와 테스트 데이터의 조합을 변경해가면서 모델을 작성하고 성능을 확인합니다. 

분류를 위해 결정 트리 인스턴스 clf를 생성합니다. 

훈련 데이터를 사용해 결정 트리 모델을 사용합니다. 

Predict를 사용해 작성한 모델에 테스트 데이터를 적용하고 결과를 취득합니다. 

accuracy_score를 사용해 결과와 답변의 정답, 오답 수로부터 모델의 성능을 계산합니다. 

numPy의 mean과 std 메서드를 이용해 모델의 평균 성능과 표준편차를 계산합니다. 

```
0.9709866705302812 0.007771887890315759
```

실행하면 모델의 평균 정확도는 0.9709..., 표준편차는 0.0077... 입니다. 

위 결과는 실행할 때 마다 변한다는 것을 주의하기 바랍니다. 

<br>

recall_score 과 Precision_score 메서드를 이용하여 재현율과 적합도 확인합니다. 

```python
from sklearn.metrics import recall_score
from sklearn.metrics import precision_score

print(recall_score(Y[test_id], pred_y))
print(precision_score(Y[test_id], pred_y))
```

recall_score은 재현율, Precision_score은 적합율을 계산하는 메서드입니다.

```
0.9629629629629629
0.9904761904761905
```

재현율은 실제 값이 T 인 값을 T로 예측한 경우의 비율입니다. 

적합율은 T 라고 예측한 값 중 실제 값이 T인 값의 비율입니다. 

설정한 분석 목표는 하와이 여행 상품 구매 확률이 높은 고객을 찾아내는 것 입니다. 

하와이 상품을 구매한 사람을 구매했다고 예측할 확률은 0.962.. 입니다. 

하와이 상품을 구매했다고 예측한 값 중 실제 하와이 상품을 구매한 확률은 0.990..입니다. 

<br>

### 파라미터 최적화

마지막으로 모델을 작성할 때 사용된 파라미터를 최적화 하겠습니다. 

파라미터는 가중치와 편향과 같은 학습을 통해 바꿔져가는 매개변수입니다. 

사용자가 결정하는 값이 아니라 기계가 훈련을 통해서 바꾸는 변수 값으로 파라미터들을 빠르고 정확하게 수렴하게 하기 위해 최적화를 진행합니다. 

<br>

우선 파라미터 기본값 확인해보겠습니다. 

```python
print(clf)
```

위의 명령을 실행하여 현재 파라미터의 기본값을 확인합니다. 

하지만 지금의 파라미터들이 최적의 조합이라고 장담할 수는 없습니다. 

그리드 서치를 사용해 모델의 성능이 가장 높아질 수 있는 파리미터의 조합을 찾아보겠습니다. 

<br>

그리드 서치를 이용해 모델의 성능을 개선해 보겠습니다. 

```python
from sklearn.model_selection import GridSearchCV

params = {
    'criterion': ['entropy'],    
    'max_depth': [2, 4, 6, 8, 10],
    'min_samples_leaf': [10, 20, 30, 40, 50],
}

clf_gs = GridSearchCV(tree.DecisionTreeClassifier(), params, 
                      cv=KFold(n_splits=10, shuffle=True), scoring='accuracy')

clf_gs.fit(X, Y)
```

그리드 서치를 사용해 모델의 성능이 가장 높아질 수 있는 파라미터의 조합을 찾아봅니다. 

```
GridSearchCV(cv=KFold(n_splits=10, random_state=None, shuffle=True),
             estimator=DecisionTreeClassifier(),
             param_grid={'criterion': ['entropy'],
                         'max_depth': [2, 4, 6, 8, 10],
                         'min_samples_leaf': [10, 20, 30, 40, 50]},
             scoring='accuracy')
```

위와 같이 그리드 서치를 실행합니다. 

<br>

가장 높은 성능일 때 모델에 대한 파라미터 조합을 확인해 보겠습니다. 

```python
print(clf_gs.best_score_)
print(clf_gs.best_params_)
```

```
0.9675601274992754
{'criterion': 'entropy', 'max_depth': 6, 'min_samples_leaf': 20}
```

실행하면 성능은 0.967..., 파라미터는 max_depth 이 6, min_samples_leaf 가 20이라는 결과가 나옵니다. 

이 결과는 실행할 때 마다 달라질 수 있다는 점을 주의하기 바랍니다. 

<br>

지금까지의 결과를 사용해 모델을 완성하고 영향력 높은 변수 확인하겠습니다. 

```python
clf_best = tree.DecisionTreeClassifier(
    criterion='entropy', max_depth=6, min_samples_leaf=20)
clf_best.fit(X, Y)

print(clf_best.feature_importances_)
```

```
[0.02323075 0.00555318 0.         0.00735941 0.         0.
 1.         0.         0.         0.         0.         0.
 2.         0.         0.         0.         0.         0.
 3.         0.         0.         0.         0.         0.
 4.         0.         0.         0.         0.         0.
 5.         0.         0.         0.         0.         0.
 6.         0.         0.         0.         0.         0.
 7.         0.         0.         0.         0.         0.
 8.         0.         0.         0.         0.         0.
 9.         0.         0.         0.         0.         0.
 10.        0.         0.         0.         0.         0.
 0.04861525 0.         0.         0.0120277  0.18375422 0.
 0.02144678 0.         0.66144037 0.         0.03657234 0.
 1.         0.         0.         0.         0.         0.
 2.         0.        ]
```

어떤 변수가 결과에 영향력이 있는지 확인할 수 있습니다. 